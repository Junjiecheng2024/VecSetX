# Phase 3 è®­ç»ƒä¸éªŒè¯é€»è¾‘æ¢³ç†

## ğŸ“Š æ ¸å¿ƒç­–ç•¥

**ä»åŸæ¥çš„**: å•ä¸€æ•°æ®é›†å†…subsetåˆ’åˆ†
**æ”¹ä¸ºç°åœ¨çš„**: åŒæ•°æ®é›†è”åˆè®­ç»ƒï¼ˆUnion of Subsetsï¼‰

---

## ğŸ—‚ï¸ æ•°æ®é›†é…ç½®

### Dataset A: Objaverse (åŸºç¡€é›†)
- **è·¯å¾„**: `/scratch/project_2016517/junjie/dataset/repaired_npz`
- **ç±»åˆ«æ•°**: 10ç±»
- **ç±»åˆ«**: `[1-10]` Myo, LA, LV, RA, RV, Ao, PA, LAA, Cor, PV
- **æ ·æœ¬æ•°**: ~798 (train)

### Dataset B: Dryad (æ‰©å±•é›†)
- **è·¯å¾„**: `/scratch/project_2016517/junjie/dataset/dryad_npz`
- **ç±»åˆ«æ•°**: 16ç±»
- **ç±»åˆ«**: 
  - `[1-10]`: ä¸Dataset Aé‡å çš„10ç±»
  - `[11-16]`: **æ–°å¢6ç±»** - SVC, IVC, RVW, LAW, CS, (1ä¸ªé¢„ç•™)
- **æ ·æœ¬æ•°**: 22

### åˆå¹¶ç´¢å¼•
- **CSVæ–‡ä»¶**: `objaverse_train_combined.csv`
- **ç”Ÿæˆè„šæœ¬**: `data_preparation/create_combined_csv.py`

---

## ğŸ‹ï¸ è®­ç»ƒé€»è¾‘ (phase3_structural/train.py)

### 1. æ•°æ®åŠ è½½

```python
# ç¬¬149-160è¡Œ
dataset_train = Objaverse(
    split='train_combined',  # ä½¿ç”¨åˆå¹¶çš„CSV
    num_classes=16,          # ç»Ÿä¸€åˆ°16ç±»
    partial_prob=0.8,        # âŒ å®é™…ä¸Šä¸ä½¿ç”¨ï¼
    min_remove=0,            # Phase 3æ ‡è¯†
    max_remove=0             # Phase 3æ ‡è¯†
)
```

**å…³é”®**ï¼š
- `split='train_combined'` â†’ åŠ è½½ `objaverse_train_combined.csv`
- CSVåŒ…å«ä¸¤ä¸ªç›®å½•çš„æ–‡ä»¶ï¼š`repaired_npz/` å’Œ `dryad_npz/`
- `num_classes=16` â†’ æ‰€æœ‰æ ·æœ¬ç»Ÿä¸€å¡«å……åˆ°16ç»´

### 2. Batchç»„æˆ

ä¸€ä¸ªBatchå¯èƒ½åŒ…å«ï¼š
```python
Batch ç¤ºä¾‹ (batch_size=2):
  æ ·æœ¬1: æ¥è‡ªDataset A (10ç±») â†’ [1,2,3,4,5,6,7,8,9,10,0,0,0,0,0,0]
  æ ·æœ¬2: æ¥è‡ªDataset B (16ç±») â†’ [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16]
```

### 3. Zero-Paddingæœºåˆ¶ (objaverse.py ç¬¬131-136è¡Œ)

```python
if orig_cols < self.num_classes:
    # Dataset A (10ç±») å¡«å……åˆ° 16ç±»
    padding = torch.zeros((N, self.num_classes - orig_cols), dtype=torch.float32)
    surface_labels_tensor = torch.cat([surface_labels_tensor, padding], dim=1)
```

### 4. Valid Class Mask (objaverse.py ç¬¬395-400è¡Œ)

```python
valid_class_mask = torch.ones(16, dtype=torch.float32)

if orig_cols < self.num_classes:
    # Dataset A: ç±»åˆ«11-16æ ‡è®°ä¸ºæ— æ•ˆ
    valid_class_mask[orig_cols:] = 0.0  # [1,1,...,1,1,0,0,0,0,0,0]
```

**ä½œç”¨**ï¼š
- Dataset Aæ ·æœ¬: `[1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0]`
- Dataset Bæ ·æœ¬: `[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1]`

### 5. Masked Loss (engine_ae.py ç¬¬129-138è¡Œ)

```python
# åˆ†ç±»æŸå¤±è®¡ç®—
loss_cls_raw = F.binary_cross_entropy_with_logits(
    pred_cls_logits, target_cls_onehot, reduction='none'
)

# åº”ç”¨maskï¼šåªåœ¨æ ·æœ¬ç¡®å®æœ‰è¯¥ç±»æ ‡ç­¾æ—¶è®¡ç®—loss
mask_expanded = class_mask.unsqueeze(1).expand_as(loss_cls_raw)
loss_cls = (loss_cls_raw * mask_expanded).sum() / mask_expanded.sum()
```

**æ•ˆæœ**ï¼š
- Dataset Aæ ·æœ¬é¢„æµ‹ç±»åˆ«11-16ä¸ä¼šè¢«æƒ©ç½šï¼ˆmask=0ï¼‰
- Dataset Bæ ·æœ¬æ‰€æœ‰16ç±»éƒ½æ­£å¸¸è®¡ç®—loss
- **é¿å…äº†çŸ¥è¯†é—å¿˜**

---

## ğŸ§ª éªŒè¯é€»è¾‘

### å½“å‰é…ç½® (ç¬¬161-169è¡Œ)

```python
dataset_val = Objaverse(
    split='val',             # ä½¿ç”¨æ™®é€šval CSV
    num_classes=16,          # ç»Ÿä¸€16ç±»
    # âŒ æ²¡æœ‰partial_probå‚æ•°ï¼
)
```

**é—®é¢˜åˆ†æ**ï¼š

1. **éªŒè¯é›†æ¥æº**: `objaverse_val.csv`
   - åªåŒ…å«Dataset Açš„éªŒè¯é›†ï¼ˆ10ç±»ï¼‰
   - ä¸åŒ…å«Dataset Bï¼ˆDryadåªæœ‰22ä¸ªæ ·æœ¬ï¼Œå¯èƒ½å…¨åœ¨è®­ç»ƒé›†ï¼‰

2. **éªŒè¯ç­–ç•¥**: å®Œæ•´è¾“å…¥ï¼ˆæ— partial maskingï¼‰
   - æ¯ä¸ªéªŒè¯æ ·æœ¬éƒ½æ˜¯å®Œæ•´çš„10ç±»è¾“å…¥
   - æµ‹è¯•çš„æ˜¯ï¼š**10ç±»é‡å»ºèƒ½åŠ›**
   - **ä¸æµ‹è¯•**ï¼šæ–°å¢6ç±»çš„å­¦ä¹ æ•ˆæœ

3. **CSVè·¯å¾„é—®é¢˜**ï¼š
   ```
   CSVæ ¼å¼: ,403.nii.img,dummy_category
   ä»£ç æœŸæœ›: category,filename,label
   å®é™…è·¯å¾„: /dataset//403.nii.img.npz (åŒæ–œæ )
   ```
   å·²é€šè¿‡æˆ‘çš„ä¿®å¤è§£å†³

---

## ğŸ¯ å…³é”®å‘ç°

### âœ… è®­ç»ƒæ—¶å‘ç”Ÿäº†ä»€ä¹ˆ

```
Epochå¾ªç¯:
  Batch 1: [DatasetAæ ·æœ¬1(10ç±»), DatasetAæ ·æœ¬2(10ç±»)]
  Batch 2: [DatasetBæ ·æœ¬1(16ç±»), DatasetBæ ·æœ¬2(16ç±»)]
  Batch 3: [DatasetAæ ·æœ¬3(10ç±»), DatasetBæ ·æœ¬3(16ç±»)] â† æ··åˆï¼
  ...
```

**æ¨¡å‹å­¦åˆ°**ï¼š
- ä»Dataset A: 10ä¸ªåŸºç¡€å¿ƒè„ç»“æ„çš„å‡ ä½•å½¢çŠ¶
- ä»Dataset B: 
  - 10ä¸ªé‡å ç±»çš„**å¦ä¸€ç§åˆ†å¸ƒ**ï¼ˆDryad vs Objaverseï¼‰
  - 6ä¸ªæ–°ç±»çš„å‡ ä½•å½¢çŠ¶ï¼ˆSVC, IVCç­‰ï¼‰
  - æ–°ç±»ä¸æ—§ç±»çš„**æ‹“æ‰‘å…³ç³»**

### âš ï¸ éªŒè¯æ—¶æ²¡æµ‹è¯•ä»€ä¹ˆ

- âŒ æ–°å¢6ç±»(11-16)çš„é‡å»ºè´¨é‡
- âŒ è·¨æ•°æ®é›†æ³›åŒ–èƒ½åŠ›
- âŒ Dataset Bæ ·æœ¬çš„æ€§èƒ½

### ğŸ”§ éªŒè¯é›†åº”è¯¥åŒ…å«ä»€ä¹ˆ

**å»ºè®®ç­–ç•¥**ï¼š
åˆ›å»ºéªŒè¯é›†æ—¶åº”è¯¥åŒ…å«ï¼š
1. Dataset Açš„valæ ·æœ¬ï¼ˆæµ‹è¯•10ç±»é‡å»ºï¼‰
2. Dataset Bçš„éƒ¨åˆ†æ ·æœ¬ï¼ˆæµ‹è¯•16ç±»é‡å»ºï¼‰

**åˆ›å»ºæ–¹æ³•**ï¼š
```bash
# ç”ŸæˆåŒ…å«ä¸¤ä¸ªæ•°æ®é›†çš„éªŒè¯CSV
python create_combined_csv.py --include_val_b
```

---

## ğŸ“Œ æ€»ç»“

### Phase 3çš„çœŸå®è®­ç»ƒé€»è¾‘

| æ–¹é¢ | å®é™…æƒ…å†µ |
|------|---------|
| **è®­ç»ƒæ•°æ®** | Dataset A (10ç±», 798) + Dataset B (16ç±», 22) |
| **è®­ç»ƒç­–ç•¥** | æ··åˆBatch + Zero-Padding + Masked Loss |
| **Partial Masking** | âŒ ä¸ä½¿ç”¨ï¼ˆ`partial_prob=0.8`ä½†`max_remove=0`ï¼‰ |
| **éªŒè¯æ•°æ®** | åªæœ‰Dataset Açš„val (10ç±») |
| **éªŒè¯ç­–ç•¥** | å®Œæ•´è¾“å…¥ï¼Œå®Œæ•´é‡å»º |
| **æ ¸å¿ƒåˆ›æ–°** | å¼‚æ„æ•°æ®é›†è”åˆè®­ç»ƒï¼Œå¢é‡å­¦ä¹  |

### å½“å‰å­˜åœ¨çš„é—®é¢˜

1. âœ… **CSVè·¯å¾„é—®é¢˜** - å·²ä¿®å¤
2. âš ï¸ **éªŒè¯é›†ä¸åŒ…å«Dataset B** - éœ€è¦æ·»åŠ 
3. âš ï¸ **æ²¡æœ‰æµ‹è¯•æ–°å¢6ç±»çš„æ€§èƒ½** - éœ€è¦per-classè¯„ä¼°

### ä¸‹ä¸€æ­¥å»ºè®®

1. **ä¿®å¤CSVè·¯å¾„** â†’ å·²å®Œæˆ
2. **åˆ›å»ºå®Œæ•´éªŒè¯é›†**ï¼šåŒ…å«Dataset A + Dataset Bçš„éªŒè¯æ ·æœ¬
3. **æ·»åŠ 16ç±»çš„per-classè¯„ä¼°**ï¼šç‰¹åˆ«å…³æ³¨ç±»åˆ«11-16
4. **ç›‘æ§Masked Loss**ï¼šç¡®ä¿Dataset Aä¸ä¼š"å¹²æ‰°"Dataset Bçš„å­¦ä¹ 

---

**Phase 3çš„æœ¬è´¨**ï¼š
> è¿™ä¸æ˜¯"ä»subsetæ¨æ–­å…¨é›†"ï¼Œè€Œæ˜¯"ä»ä¸¤ä¸ªä¸åŒåˆ†å¸ƒçš„æ•°æ®é›†ä¸­å­¦ä¹ ç»Ÿä¸€çš„16ç±»å¿ƒè¡€ç®¡è¡¨ç¤º"ã€‚

è¿™æ˜¯ä¸€ä¸ª**å¢é‡å­¦ä¹ ï¼ˆIncremental Learningï¼‰**é—®é¢˜ï¼Œè€Œéè¡¥å…¨é—®é¢˜ï¼
